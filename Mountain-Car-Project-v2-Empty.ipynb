{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mountain-Car-Project-v2-Empty.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"npNX7e5yGnf7","colab_type":"text"},"cell_type":"markdown","source":["# Welcome to your first AI game!\n"]},{"metadata":{"id":"nFZaT_CWGnf9","colab_type":"text"},"cell_type":"markdown","source":["Let's create the environment!"]},{"metadata":{"id":"m1o7nKuZGnf-","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 0--\n","# Import and initialize Mountain Car Environment\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7hY-bXWeGngB","colab_type":"text"},"cell_type":"markdown","source":["Set the given variables and then discretize the range of position(num_states[0]) and velocity(num_states[1]) and print the size of bins/discete values."]},{"metadata":{"id":"nvp5bzkMGngC","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 1--\n","\n","# Set the variables\n","\n","# Determine size of discretized state space\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j2i1C88-GngF","colab_type":"text"},"cell_type":"markdown","source":["Create 2 empty tables for Reward & Avg. Reward and Initialize Q-Table with random values\n"]},{"metadata":{"id":"Qb86VZTZGngF","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 2--\n","\n","# Initialize variables to track rewards\n","\n","\n","# Initialize Q table\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y2GXVnsuGngI","colab_type":"text"},"cell_type":"markdown","source":["Apply the Q-Learning algorithm for 1 episode:"]},{"metadata":{"id":"nddlQ_HtGngJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 3--\n","\n","# Initialize parameters (done,state,rewards)\n","\n","        \n","        \n","# Discretize state\n","\n","\n","\n","            "],"execution_count":0,"outputs":[]},{"metadata":{"id":"4lxkMvb9GngL","colab_type":"text"},"cell_type":"markdown","source":["Create the loop in order to move the car."]},{"metadata":{"id":"3wlT6x-MGngM","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 4--\n","\n","#Create a loop that is terminated when the game is won\n","#MAKE SURE THAT YOUR CODE IS ALLIGNED CORRECTLY \n","\n","#while \n","        \n","    # Render environment\n","    \n","            \n","                \n","    # Determine next action - epsilon greedy strategy\n","    \n","    \n","    \n","    # Get next state and reward\n","   \n","            \n","            \n","    # Discretize new state\n","    \n","\n","            \n","    #Allow for terminal states\n","    #if \n","            \n","        \n","    # Adjust Q value for current state / Apply the Q-Learning function\n","    #else:\n","         \n","                \n","            \n","              \n","    # Update variables\n","    \n","\n","#Close the environment after the loop    \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kL0EII5RGngP","colab_type":"text"},"cell_type":"markdown","source":["After creating successfully the code for a single episode, you are now ready to insert your code in a loop for many episodes so that the mountain car can learn how to win through the Q-Learning algorithm!"]},{"metadata":{"id":"HW6z-uM9GngP","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 5--\n","\n","# Calculate episodic reduction in epsilon\n","\n","\n","\n","#Create the loop for the episodes assigned in the beginning of the code and put inside the code from STEP 3 \n","#AND STEP 4 but now close the environment at the end of for loop and\n","#Rememer to render the environment every 200 episodes this time\n","\n","\n","#MAKE SURE THAT YOUR CODE IS ALLIGNED CORRECTLY \n","\n","\n","#for\n","    \n","    #PUT YOUR CODE HERE , RENDER EVERY 200 EPISODES\n","        \n","    # Inside the for loop you need to decay epsilon\n","  \n","    # Track rewards\n","    \n","        \n","    \n","  \n","\n","\n","    #LOOP ENDS HERE\n","    \n","    \n"," #After creating the loop remember to CLOSE the environment of mountain car\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pA7SNNzrGngS","colab_type":"text"},"cell_type":"markdown","source":["Evaluate how well our code responses through plotting the Average Reward dependent upon episode"]},{"metadata":{"id":"m9ugOGzuGngT","colab_type":"code","colab":{}},"cell_type":"code","source":["# --STEP 6--\n","\n","# Plot Rewards\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RnrETadPGngW","colab_type":"text"},"cell_type":"markdown","source":["# Good job, your car made it to the top!!"]}]}